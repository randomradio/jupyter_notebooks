{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/randomradio/jupyter_notebooks/blob/main/gemini/use-cases/video-analysis/youtube_video_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ur8xi4C7S06n"
      },
      "outputs": [],
      "source": [
        "# Copyright 2024 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAPoU8Sm5E6e"
      },
      "source": [
        "# YouTube Video Analysis with Gemini\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/video-analysis/youtube_video_analysis.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://www.gstatic.com/pantheon/images/bigquery/welcome_page/colab-logo.svg\" alt=\"Google Colaboratory logo\"><br> Open in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fgenerative-ai%2Fmain%2Fgemini%2Fuse-cases%2Fvideo-analysis%2Fyoutube_video_analysis.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"><br> Open in Colab Enterprise\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/gemini/use-cases/video-analysis/youtube_video_analysis.ipynb\">\n",
        "      <img src=\"https://www.gstatic.com/images/branding/gcpiconscolors/vertexai/v1/32px.svg\" alt=\"Vertex AI logo\"><br> Open in Vertex AI Workbench\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/video-analysis/youtube_video_analysis.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://upload.wikimedia.org/wikipedia/commons/9/91/Octicons-mark-github.svg\" alt=\"GitHub logo\"><br> View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "</table>\n",
        "\n",
        "<div style=\"clear: both;\"></div>\n",
        "\n",
        "<b>Share to:</b>\n",
        "\n",
        "<a href=\"https://www.linkedin.com/sharing/share-offsite/?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/video-analysis/youtube_video_analysis.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/8/81/LinkedIn_icon.svg\" alt=\"LinkedIn logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://bsky.app/intent/compose?text=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/video-analysis/youtube_video_analysis.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/7/7a/Bluesky_Logo.svg\" alt=\"Bluesky logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://twitter.com/intent/tweet?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/video-analysis/youtube_video_analysis.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/53/X_logo_2023_original.svg\" alt=\"X logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://reddit.com/submit?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/video-analysis/youtube_video_analysis.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://redditinc.com/hubfs/Reddit%20Inc/Brand/Reddit_Logo.png\" alt=\"Reddit logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://www.facebook.com/sharer/sharer.php?u=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/video-analysis/youtube_video_analysis.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/51/Facebook_f_logo_%282019%29.svg\" alt=\"Facebook logo\">\n",
        "</a>            "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84f0f73a0f76"
      },
      "source": [
        "| | |\n",
        "|-|-|\n",
        "| Author(s) | [Alok Pattani](https://github.com/alokpattani/) |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvgnzT1CKxrO"
      },
      "source": [
        "## Overview\n",
        "\n",
        "In this notebook, you'll explore how to do direct analysis of publicly available [YouTube](https://www.youtube.com/) videos with Gemini.\n",
        "\n",
        "You will complete the following tasks:\n",
        "\n",
        "- Summarizing a single YouTube video using Gemini 2.0 Flash\n",
        "- Extracting a specific set of structured outputs from a longer YouTube video using Gemini 2.0 Pro and controlled generation\n",
        "- Creating insights from analyzing multiple YouTube videos together using asynchronous generation with Gemini"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61RBz8LLbxCR"
      },
      "source": [
        "## Get started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "No17Cw5hgx12"
      },
      "source": [
        "### Install Google Gen AI SDK and other required packages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tFy3H3aPgx12",
        "outputId": "5c145e64-6d94-4f91-fd7f-a0c878246f15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/137.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.7/137.7 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade --quiet google-genai itables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5Xep4W9lq-Z"
      },
      "source": [
        "### Restart runtime\n",
        "\n",
        "To use the newly installed packages in this Jupyter runtime, you must restart the runtime. You can do this by running the cell below, which restarts the current kernel.\n",
        "\n",
        "The restart might take a minute or longer. After it's restarted, continue to the next step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "XRvKdaPDTznN",
        "outputId": "99eefbb6-9453-4935-928b-b2e04126be97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'status': 'ok', 'restart': True}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import IPython\n",
        "\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbmM4z7FOBpM"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "<b>⚠️ The kernel is going to restart. Wait until it's finished before continuing to the next step. ⚠️</b>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmWOrTJ3gx13"
      },
      "source": [
        "### Authenticate your notebook environment (Colab only)\n",
        "\n",
        "If you're running this notebook on Google Colab, run the cell below to authenticate your environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "NyKGtVQjgx13"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DF4l8DTdWgPY"
      },
      "source": [
        "### Set Google Cloud project information and create client\n",
        "\n",
        "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
        "\n",
        "Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Nqwi-5ufWp_B"
      },
      "outputs": [],
      "source": [
        "# Use the environment variable if the user doesn't provide Project ID.\n",
        "import os\n",
        "\n",
        "PROJECT_ID = \"gen-lang-client-0410749374\"  # @param {type: \"string\", placeholder: \"[your-project-id]\", isTemplate: true}\n",
        "if not PROJECT_ID or PROJECT_ID == \"[your-project-id]\":\n",
        "    PROJECT_ID = str(os.environ.get(\"GOOGLE_CLOUD_PROJECT\"))\n",
        "\n",
        "LOCATION = os.environ.get(\"GOOGLE_CLOUD_REGION\", \"us-central1\")\n",
        "\n",
        "from google import genai\n",
        "\n",
        "client = genai.Client(vertexai=True, project=PROJECT_ID, location=LOCATION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdvJRUWRNGHE"
      },
      "source": [
        "## Set up libraries, options, and models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5303c05f7aa6"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6fc324893334"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "from IPython.display import HTML, Markdown, display\n",
        "from google.genai.types import GenerateContentConfig, Part\n",
        "from itables import show\n",
        "import itables.options as itable_opts\n",
        "import pandas as pd\n",
        "from tenacity import retry, stop_after_attempt, wait_random_exponential"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f86c665a5d94"
      },
      "source": [
        "### Configure some notebook options"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4730b9f09e1e"
      },
      "outputs": [],
      "source": [
        "# Configure some options related to interactive tables\n",
        "itable_opts.maxBytes = 1e9\n",
        "itable_opts.maxColumns = 50\n",
        "\n",
        "itable_opts.order = []\n",
        "itable_opts.column_filters = \"header\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9d46fd0dfdf7"
      },
      "source": [
        "### Create a helper function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "e9034b0991f4"
      },
      "outputs": [],
      "source": [
        "def display_youtube_video(url: str) -> None:\n",
        "    youtube_video_embed_url = url.replace(\"/watch?v=\", \"/embed/\")\n",
        "\n",
        "    # Create HTML code to directly embed video\n",
        "    youtube_video_embed_html_code = f\"\"\"\n",
        "    <iframe width=\"560\" height=\"315\" src=\"{youtube_video_embed_url}\"\n",
        "    title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay;\n",
        "    clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen>\n",
        "    </iframe>\n",
        "    \"\"\"\n",
        "\n",
        "    # Display embedded YouTube video\n",
        "    display(HTML(youtube_video_embed_html_code))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e43229f3ad4f"
      },
      "source": [
        "### Load models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "cf93d5f0ce00"
      },
      "outputs": [],
      "source": [
        "# Set Gemini Flash and Pro models to be used in this notebook\n",
        "GEMINI_FLASH_MODEL_ID = \"gemini-2.0-flash-001\"\n",
        "GEMINI_PRO_MODEL_ID = \"gemini-2.0-pro-exp-02-05\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "109111fae02c"
      },
      "source": [
        "## Summarize a YouTube video"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fe7e2663c3a"
      },
      "source": [
        "Provide a link to a public YouTube video that you'd like to summarize. Ensure that the video is less than an hour long (if using Gemini 1.5 Flash, as is shown below; can try up to a 2-hour video with Gemini 1.5 Pro) to make sure it fits in the context window.\n",
        "\n",
        "The default content to be summarized is [this 6.5-minute video showing how Major League Baseball (MLB) analyzes data using Google Cloud](https://www.youtube.com/watch?v=O_W_VGUeHVI)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "5c8a32e14eec",
        "outputId": "fc1979f7-81b2-43e4-c1ca-d6fadc88d77d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/O_W_VGUeHVI\"\n",
              "    title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; \n",
              "    clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen>\n",
              "    </iframe>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Provide link to a public YouTube video to summarize\n",
        "YOUTUBE_VIDEO_URL = (\n",
        "    \"https://www.youtube.com/watch?v=O_W_VGUeHVI\"  # @param {type:\"string\"}\n",
        ")\n",
        "\n",
        "display_youtube_video(YOUTUBE_VIDEO_URL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9bd742163fc7",
        "outputId": "00dd8509-b79f-440b-dcf9-a802fbe650dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Here’s a detailed summary of the video:\n\nThe video titled “The Big Leagues of Data” is about how Major League Baseball uses Google Cloud. The announcer explains how statistics in baseball have been kept for over one hundred years, but it has become possible to answer many new intuitive questions. MLB has teamed up with Google Cloud to explore data possibilities on and off the field.\n\nPriyanka Vergadia, Lead Developer Advocate at Google, is on a mission to find out just how they’ve done it. Josh Frost, VP, product management at MLB, says that 25 million unique data points are captured in an individual game and there are 2430 regular season games each year. This creates unique challenges for delivering data to customers. \n\nAlok Pattani, a data science developer advocate at Google, says one of the most powerful things MLB has done is combine the data to the video with MLB Film Room. Now, both ball and players can be tracked several times each second. There needs to be the right instrumentation and the right technologies to help process this data and answer the type of questions you get with that data.\n\nRob Engel, Senior Director, Software Engineering at MLB, shares how the data on the field is processed by using Anthos. This deployed Kubernetes is inside the ballpark, then data is sent from the ballpark Kubernetes to the Kubernetes cluster running in Google Cloud. From there, it scales out and is stored in Cloud SQL for a database and read back into a stats API to serve the information to millions of fans around the world in real time. He also explains the use of the Big Table, an awesome resource to use for pose tracking data, which they call Field Vision. \n\nBrian Kenny, Sportscaster and Host at MLB now, says that now how to find answers is frequently in the data. Sara Langs, a reporter/researcher at MLB Advanced Media, uses a combination of website resources like baseball savant, fangraph, and baseball reference and is able to tell how fast the pitch was and how hard the ball was hit.\n\nPriyanka Vergadia concludes by saying that data and analytics in the cloud are powerful tools, and it’s been an amazing learning experience how it’s applied in the sports world today."
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Call Gemini API with prompt to summarize video\n",
        "video_summary_prompt = \"Give a detailed summary of this video.\"\n",
        "\n",
        "video_summary_response = client.models.generate_content(\n",
        "    model=GEMINI_FLASH_MODEL_ID,\n",
        "    contents=[\n",
        "        Part.from_uri(\n",
        "            file_uri=YOUTUBE_VIDEO_URL,\n",
        "            mime_type=\"video/webm\",\n",
        "        ),\n",
        "        video_summary_prompt,\n",
        "    ],\n",
        ")\n",
        "\n",
        "# Display results\n",
        "display(Markdown(video_summary_response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09221a4ba6a9"
      },
      "source": [
        "## Extract structured output from a YouTube video"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "db6bc26fca7d"
      },
      "source": [
        "Next, we'll show how to extract structured outputs using [controlled generation](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/control-generated-output), in this case from a video that covers multiple topics.\n",
        "\n",
        "We're going to see how Gemini Pro's industry-leading 2 million token context window can help analyze [the full opening keynote](https://www.youtube.com/watch?v=V6DJYGn2SFk) from our Next conference back in April - all 1 hour and 41 minutes of it!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "fc98b36d5fc4",
        "outputId": "e560aa0a-6d75-4add-d7c0-9f298e410c56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/M-CzbTUVykg\"\n",
              "    title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; \n",
              "    clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen>\n",
              "    </iframe>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Link to full Cloud Next '24 Opening Keynote video\n",
        "# cloud_next_keynote_video_url = \"https://www.youtube.com/watch?v=V6DJYGn2SFk\"\n",
        "\n",
        "# Uncomment line below to replace with 14-min keynote summary video instead (faster)\n",
        "cloud_next_keynote_video_url = \"https://www.youtube.com/watch?v=M-CzbTUVykg\"\n",
        "\n",
        "display_youtube_video(cloud_next_keynote_video_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e904c020d521"
      },
      "source": [
        "Below is a prompt to extract the biggest product announcements that were made during this keynote. We use the response schema to show that we want valid JSON output in a particular form, including a constraint specifying that the \"product status\" field should be either GA, Preview, or Coming Soon.\n",
        "\n",
        "The following cell may take several minutes to run, as Gemini 2.0 Pro is analyzing all 101 minutes of the video and audio to produce comprehensive results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "d5a93cd5d2fa",
        "outputId": "f074bd6d-fce2-44a9-90da-418d3a17ab62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "  {\n",
            "    \"name\": \"Gemini 1.5 Pro\",\n",
            "    \"product_status\": \"Preview\",\n",
            "    \"quote_from_presenter\": \"1.  5 Pro shows dramatically enhanced performance, and includes a breakthrough in long context understanding.\"\n",
            "  },\n",
            "  {\n",
            "    \"name\": \"Imagen 2.0\",\n",
            "    \"product_status\": \"GA\",\n",
            "    \"quote_from_presenter\": \"Our most advanced text-to-image technology.\"\n",
            "  },\n",
            "  {\n",
            "    \"name\": \"Text-to-Live Image\",\n",
            "    \"product_status\": \"Preview\",\n",
            "    \"quote_from_presenter\": \"Marketing and creative teams can generate animated images from a text prompt, including product images, ads, GIFs, and storyboards.\"\n",
            "  },\n",
            "  {\n",
            "    \"name\": \"Google Vids\",\n",
            "    \"product_status\": \"Coming Soon\",\n",
            "    \"quote_from_presenter\": \"Google Vids is an AI-powered video creation app for work.\"\n",
            "  },\n",
            "  {\n",
            "    \"name\": \"AI Meetings and Messaging Add-on\",\n",
            "    \"product_status\": \"GA\",\n",
            "    \"quote_from_presenter\": \"With take notes for me, chat summarization, and real-time translation.\"\n",
            "  },\n",
            "  {\n",
            "    \"name\": \"AI Security Add-on\",\n",
            "    \"product_status\": \"GA\",\n",
            "    \"quote_from_presenter\": \"We're making AI-powered data protection available with our brand-new AI Security add-on.\"\n",
            "  },\n",
            "  {\n",
            "    \"name\": \"Gemini in Google Chat\",\n",
            "    \"product_status\": \"Preview\",\n",
            "    \"quote_from_presenter\": \"Gemini and Chat can now catch you up on long conversation threads, summarize decisions, and be a real-time creative partner.\"\n",
            "  },\n",
            "  {\n",
            "    \"name\": \"Gemini Code Assist\",\n",
            "    \"product_status\": \"GA\",\n",
            "    \"quote_from_presenter\": \"Our enterprise-focused AI code assistants is now called Gemini Code Assist.\"\n",
            "  },\n",
            "  {\n",
            "    \"name\": \"Gemini Cloud Assist\",\n",
            "    \"product_status\": \"Preview\",\n",
            "    \"quote_from_presenter\": \"Making it easier to design, secure, operate, troubleshoot, and optimize your applications.\"\n",
            "  },\n",
            "  {\n",
            "    \"name\": \"Gemini in Threat Intelligence\",\n",
            "    \"product_status\": \"Preview\",\n",
            "    \"quote_from_presenter\": \"Enables you to use natural language prompts to get deep insight about threat behavior actors.\"\n",
            "  },\n",
            "  {\n",
            "    \"name\": \"Vertex AI Agent Builder\",\n",
            "    \"product_status\": \"GA\",\n",
            "    \"quote_from_presenter\": \"You can now create customer agents that are amazingly powerful in just three key steps.\"\n",
            "  },\n",
            "  {\n",
            "    \"name\": \"A3 Mega VMs\",\n",
            "    \"product_status\": \"GA\",\n",
            "    \"quote_from_presenter\": \"Powered by NVIDIA H100 Tensor Core GPUs with twice the network bandwidth per GPU compared to A3 instances.\"\n",
            "  },\n",
            "  {\n",
            "    \"name\": \"NVIDIA GB200 NVL72\",\n",
            "    \"product_status\": \"Coming Soon\",\n",
            "    \"quote_from_presenter\": \"NVIDIA's newest Grace Blackwell generation of GPUs coming to Google Cloud early in 2025.\"\n",
            "  },\n",
            "  {\n",
            "    \"name\": \"Hyperdisk ML\",\n",
            "    \"product_status\": \"Preview\",\n",
            "    \"quote_from_presenter\": \"Our next generation block storage service optimized for AI inference and serving workloads.\"\n",
            "  },\n",
            "  {\n",
            "    \"name\": \"Google Axion Processors\",\n",
            "    \"product_status\": \"Preview\",\n",
            "    \"quote_from_presenter\": \"It's our first custom arm-based CPU designed for the data center.\"\n",
            "  },\n",
            "  {\n",
            "    \"name\": \"Vector Indexing in BigQuery and AlloyDB\",\n",
            "    \"product_status\": \"Preview\",\n",
            "    \"quote_from_presenter\": \"This allows you to leverage AI over your data where it is stored, enabling real-time and accurate responses for AI applications.\"\n",
            "  },\n",
            "  {\n",
            "    \"name\": \"Direct Access to Vertex AI from BigQuery\",\n",
            "    \"product_status\": \"Preview\",\n",
            "    \"quote_from_presenter\": \"To give you direct access to AI models in Vertex from BigQuery.\"\n",
            "  }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "# Set up pieces (prompt, response schema, config) and run video extraction\n",
        "\n",
        "video_extraction_prompt = (\n",
        "    \"Provide a summary of the biggest product announcements \"\n",
        "    \"that were made in this Google Cloud Next keynote video including:\\n\"\n",
        "    \"  - name\\n\"\n",
        "    '  - product status: \"GA\" (Generally Available), \"Preview\", or \"Coming Soon\"\\n'\n",
        "    \"  - key quote from the presenter about the product, 20 words or fewer per product\\n\\n\"\n",
        "    \"Make sure to look through and listen to the whole video, start to finish, to find \"\n",
        "    \"the top product announcements. Only reference information in the video itself in \"\n",
        "    \"your response.\"\n",
        ")\n",
        "\n",
        "video_extraction_response_schema = {\n",
        "    \"type\": \"ARRAY\",\n",
        "    \"items\": {\n",
        "        \"type\": \"OBJECT\",\n",
        "        \"properties\": {\n",
        "            \"name\": {\"type\": \"STRING\"},\n",
        "            \"product_status\": {\n",
        "                \"type\": \"STRING\",\n",
        "                \"enum\": [\"GA\", \"Preview\", \"Coming Soon\"],\n",
        "            },\n",
        "            \"quote_from_presenter\": {\"type\": \"STRING\"},\n",
        "        },\n",
        "    },\n",
        "}\n",
        "\n",
        "video_extraction_json_generation_config = GenerateContentConfig(\n",
        "    temperature=0.0,\n",
        "    max_output_tokens=8192,\n",
        "    response_mime_type=\"application/json\",\n",
        "    response_schema=video_extraction_response_schema,\n",
        ")\n",
        "\n",
        "video_extraction_response = client.models.generate_content(\n",
        "    model=GEMINI_PRO_MODEL_ID,\n",
        "    contents=[\n",
        "        video_extraction_prompt,\n",
        "        Part.from_uri(\n",
        "            file_uri=cloud_next_keynote_video_url,\n",
        "            mime_type=\"video/webm\",\n",
        "        ),\n",
        "    ],\n",
        "    config=video_extraction_json_generation_config,\n",
        ")\n",
        "\n",
        "print(video_extraction_response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "b7b6aa978eb8",
        "outputId": "42b76f66-b803-46ef-cd72-a25ceea13319",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table id=\"itables_a2af6593_5fe1_43a1_b47f_005dca030d1d\" class=\"display nowrap\" data-quarto-disable-processing=\"true\" style=\"table-layout:auto;width:auto;margin:auto;caption-side:bottom\">\n",
              "<thead><th>name</th><th>product_status</th><th>quote_from_presenter</th></thead><tbody><tr>\n",
              "<td style=\"vertical-align:middle; text-align:left\">\n",
              "<a href=https://mwouts.github.io/itables/><svg class=\"main-svg\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\n",
              "width=\"64\" viewBox=\"0 0 500 400\" style=\"font-family: 'Droid Sans', sans-serif;\">\n",
              "    <g style=\"fill:#d9d7fc\">\n",
              "        <path d=\"M100,400H500V357H100Z\" />\n",
              "        <path d=\"M100,300H400V257H100Z\" />\n",
              "        <path d=\"M0,200H400V157H0Z\" />\n",
              "        <path d=\"M100,100H500V57H100Z\" />\n",
              "        <path d=\"M100,350H500V307H100Z\" />\n",
              "        <path d=\"M100,250H400V207H100Z\" />\n",
              "        <path d=\"M0,150H400V107H0Z\" />\n",
              "        <path d=\"M100,50H500V7H100Z\" />\n",
              "    </g>\n",
              "    <g style=\"fill:#1a1366;stroke:#1a1366;\">\n",
              "   <rect x=\"100\" y=\"7\" width=\"400\" height=\"43\">\n",
              "    <animate\n",
              "      attributeName=\"width\"\n",
              "      values=\"0;400;0\"\n",
              "      dur=\"5s\"\n",
              "      repeatCount=\"indefinite\" />\n",
              "      <animate\n",
              "      attributeName=\"x\"\n",
              "      values=\"100;100;500\"\n",
              "      dur=\"5s\"\n",
              "      repeatCount=\"indefinite\" />\n",
              "  </rect>\n",
              "        <rect x=\"0\" y=\"107\" width=\"400\" height=\"43\">\n",
              "    <animate\n",
              "      attributeName=\"width\"\n",
              "      values=\"0;400;0\"\n",
              "      dur=\"3.5s\"\n",
              "      repeatCount=\"indefinite\" />\n",
              "    <animate\n",
              "      attributeName=\"x\"\n",
              "      values=\"0;0;400\"\n",
              "      dur=\"3.5s\"\n",
              "      repeatCount=\"indefinite\" />\n",
              "  </rect>\n",
              "        <rect x=\"100\" y=\"207\" width=\"300\" height=\"43\">\n",
              "    <animate\n",
              "      attributeName=\"width\"\n",
              "      values=\"0;300;0\"\n",
              "      dur=\"3s\"\n",
              "      repeatCount=\"indefinite\" />\n",
              "    <animate\n",
              "      attributeName=\"x\"\n",
              "      values=\"100;100;400\"\n",
              "      dur=\"3s\"\n",
              "      repeatCount=\"indefinite\" />\n",
              "  </rect>\n",
              "        <rect x=\"100\" y=\"307\" width=\"400\" height=\"43\">\n",
              "    <animate\n",
              "      attributeName=\"width\"\n",
              "      values=\"0;400;0\"\n",
              "      dur=\"4s\"\n",
              "      repeatCount=\"indefinite\" />\n",
              "      <animate\n",
              "      attributeName=\"x\"\n",
              "      values=\"100;100;500\"\n",
              "      dur=\"4s\"\n",
              "      repeatCount=\"indefinite\" />\n",
              "  </rect>\n",
              "        <g style=\"fill:transparent;stroke-width:8; stroke-linejoin:round\" rx=\"5\">\n",
              "            <g transform=\"translate(45 50) rotate(-45)\">\n",
              "                <circle r=\"33\" cx=\"0\" cy=\"0\" />\n",
              "                <rect x=\"-8\" y=\"32\" width=\"16\" height=\"30\" />\n",
              "            </g>\n",
              "\n",
              "            <g transform=\"translate(450 152)\">\n",
              "                <polyline points=\"-15,-20 -35,-20 -35,40 25,40 25,20\" />\n",
              "                <rect x=\"-15\" y=\"-40\" width=\"60\" height=\"60\" />\n",
              "            </g>\n",
              "\n",
              "            <g transform=\"translate(50 352)\">\n",
              "                <polygon points=\"-35,-5 0,-40 35,-5\" />\n",
              "                <polygon points=\"-35,10 0,45 35,10\" />\n",
              "            </g>\n",
              "\n",
              "            <g transform=\"translate(75 250)\">\n",
              "                <polyline points=\"-30,30 -60,0 -30,-30\" />\n",
              "                <polyline points=\"0,30 -30,0 0,-30\" />\n",
              "            </g>\n",
              "\n",
              "            <g transform=\"translate(425 250) rotate(180)\">\n",
              "                <polyline points=\"-30,30 -60,0 -30,-30\" />\n",
              "                <polyline points=\"0,30 -30,0 0,-30\" />\n",
              "            </g>\n",
              "        </g>\n",
              "    </g>\n",
              "</svg>\n",
              "</a>\n",
              "Loading ITables v2.2.5 from the internet...\n",
              "(need <a href=https://mwouts.github.io/itables/troubleshooting.html>help</a>?)</td>\n",
              "</tr></tbody>\n",
              "</table>\n",
              "<link href=\"https://www.unpkg.com/dt_for_itables@2.0.13/dt_bundle.css\" rel=\"stylesheet\">\n",
              "<script type=\"module\">\n",
              "    import {DataTable, jQuery as $} from 'https://www.unpkg.com/dt_for_itables@2.0.13/dt_bundle.js';\n",
              "\n",
              "    document.querySelectorAll(\"#itables_a2af6593_5fe1_43a1_b47f_005dca030d1d:not(.dataTable)\").forEach(table => {\n",
              "        if (!(table instanceof HTMLTableElement))\n",
              "            return;\n",
              "\n",
              "        // Define the table data\n",
              "        const data = [[\"Gemini 1.5 Pro\", \"Preview\", \"1.  5 Pro shows dramatically enhanced performance, and includes a breakthrough in long context understanding.\"], [\"Imagen 2.0\", \"GA\", \"Our most advanced text-to-image technology.\"], [\"Text-to-Live Image\", \"Preview\", \"Marketing and creative teams can generate animated images from a text prompt, including product images, ads, GIFs, and storyboards.\"], [\"Google Vids\", \"Coming Soon\", \"Google Vids is an AI-powered video creation app for work.\"], [\"AI Meetings and Messaging Add-on\", \"GA\", \"With take notes for me, chat summarization, and real-time translation.\"], [\"AI Security Add-on\", \"GA\", \"We're making AI-powered data protection available with our brand-new AI Security add-on.\"], [\"Gemini in Google Chat\", \"Preview\", \"Gemini and Chat can now catch you up on long conversation threads, summarize decisions, and be a real-time creative partner.\"], [\"Gemini Code Assist\", \"GA\", \"Our enterprise-focused AI code assistants is now called Gemini Code Assist.\"], [\"Gemini Cloud Assist\", \"Preview\", \"Making it easier to design, secure, operate, troubleshoot, and optimize your applications.\"], [\"Gemini in Threat Intelligence\", \"Preview\", \"Enables you to use natural language prompts to get deep insight about threat behavior actors.\"], [\"Vertex AI Agent Builder\", \"GA\", \"You can now create customer agents that are amazingly powerful in just three key steps.\"], [\"A3 Mega VMs\", \"GA\", \"Powered by NVIDIA H100 Tensor Core GPUs with twice the network bandwidth per GPU compared to A3 instances.\"], [\"NVIDIA GB200 NVL72\", \"Coming Soon\", \"NVIDIA's newest Grace Blackwell generation of GPUs coming to Google Cloud early in 2025.\"], [\"Hyperdisk ML\", \"Preview\", \"Our next generation block storage service optimized for AI inference and serving workloads.\"], [\"Google Axion Processors\", \"Preview\", \"It's our first custom arm-based CPU designed for the data center.\"], [\"Vector Indexing in BigQuery and AlloyDB\", \"Preview\", \"This allows you to leverage AI over your data where it is stored, enabling real-time and accurate responses for AI applications.\"], [\"Direct Access to Vertex AI from BigQuery\", \"Preview\", \"To give you direct access to AI models in Vertex from BigQuery.\"]];\n",
              "\n",
              "        // Define the dt_args\n",
              "        let dt_args = {\"layout\": {\"topStart\": \"pageLength\", \"topEnd\": \"search\", \"bottomStart\": \"info\", \"bottomEnd\": \"paging\"}, \"order\": [], \"warn_on_selected_rows_not_rendered\": true, \"initComplete\": function () {\n",
              "    // Apply the search\n",
              "    this.api()\n",
              "        .columns()\n",
              "        .every(function () {\n",
              "            const that = this;\n",
              "\n",
              "            $('input', this.header()).on('keyup change clear', function () {\n",
              "                if (that.search() !== this.value) {\n",
              "                    that.search(this.value).draw();\n",
              "                }\n",
              "            });\n",
              "        });\n",
              "}\n",
              "};\n",
              "        dt_args[\"data\"] = data;\n",
              "\n",
              "        // Setup - add a text input to each header or footer cell\n",
              "$('#itables_a2af6593_5fe1_43a1_b47f_005dca030d1d:not(.dataTable) thead th').each(function () {\n",
              "    var input = document.createElement(\"input\");\n",
              "    input.type = \"text\";\n",
              "    input.placeholder = \"Search \" + $(this).text();\n",
              "\n",
              "    $(this).html(input);\n",
              "});\n",
              "\n",
              "        new DataTable(table, dt_args);\n",
              "    });\n",
              "</script>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Convert structured output from response to data frame for display and/or further analysis\n",
        "video_extraction_response_df = pd.DataFrame(video_extraction_response.parsed)\n",
        "\n",
        "show(video_extraction_response_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfa2e8496790"
      },
      "source": [
        "## Creating insights from analyzing multiple YouTube videos together"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c634255fd419"
      },
      "source": [
        "### Google \"Year in Search\" videos\n",
        "Now, consider expanding the problem to a more common enterprise use case: extracting information from _multiple_ YouTube videos at once.\n",
        "\n",
        "This time, we'll use [Google's \"Year in Search\" videos](https://about.google/intl/ALL_us/stories/year-in-search/), which summarize the questions, people, and moments that captured the world's attention in each year. As of fall 2024, there are 14 of these videos, each 2-4 minutes in length, from [2010](https://www.youtube.com/watch?v=F0QXB5pw2qE) through [2023](https://www.youtube.com/watch?v=3KtWfp0UopM).\n",
        "\n",
        "We start by reading in a CSV file that has links to all the videos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "b004061c908a",
        "outputId": "7a1fd4bf-5f97-4d00-b9e6-8ec8b0258702",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    year                                      yt_link\n",
              "0   2023  https://www.youtube.com/watch?v=3KtWfp0UopM\n",
              "1   2022  https://www.youtube.com/watch?v=4WXs3sKu41I\n",
              "2   2021  https://www.youtube.com/watch?v=EqboAI-Vk-U\n",
              "3   2020  https://www.youtube.com/watch?v=rokGy0huYEA\n",
              "4   2019  https://www.youtube.com/watch?v=ZRCdORJiUgU\n",
              "5   2018  https://www.youtube.com/watch?v=6aFdEhEZQjE\n",
              "6   2017  https://www.youtube.com/watch?v=vI4LHl4yFuo\n",
              "7   2016  https://www.youtube.com/watch?v=KIViy7L_lo8\n",
              "8   2015  https://www.youtube.com/watch?v=q7o7R5BgWDY\n",
              "9   2014  https://www.youtube.com/watch?v=DVwHCGAr_OE\n",
              "10  2013  https://www.youtube.com/watch?v=Lv-sY_z8MNs\n",
              "11  2012  https://www.youtube.com/watch?v=xY_MUB8adEQ\n",
              "12  2011  https://www.youtube.com/watch?v=SAIEamakLoY\n",
              "13  2010  https://www.youtube.com/watch?v=F0QXB5pw2qE"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-018e8de5-c9e5-4574-80a3-59f4949362d8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>yt_link</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2023</td>\n",
              "      <td>https://www.youtube.com/watch?v=3KtWfp0UopM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2022</td>\n",
              "      <td>https://www.youtube.com/watch?v=4WXs3sKu41I</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021</td>\n",
              "      <td>https://www.youtube.com/watch?v=EqboAI-Vk-U</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020</td>\n",
              "      <td>https://www.youtube.com/watch?v=rokGy0huYEA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2019</td>\n",
              "      <td>https://www.youtube.com/watch?v=ZRCdORJiUgU</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2018</td>\n",
              "      <td>https://www.youtube.com/watch?v=6aFdEhEZQjE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2017</td>\n",
              "      <td>https://www.youtube.com/watch?v=vI4LHl4yFuo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2016</td>\n",
              "      <td>https://www.youtube.com/watch?v=KIViy7L_lo8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2015</td>\n",
              "      <td>https://www.youtube.com/watch?v=q7o7R5BgWDY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2014</td>\n",
              "      <td>https://www.youtube.com/watch?v=DVwHCGAr_OE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>2013</td>\n",
              "      <td>https://www.youtube.com/watch?v=Lv-sY_z8MNs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>2012</td>\n",
              "      <td>https://www.youtube.com/watch?v=xY_MUB8adEQ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>2011</td>\n",
              "      <td>https://www.youtube.com/watch?v=SAIEamakLoY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>2010</td>\n",
              "      <td>https://www.youtube.com/watch?v=F0QXB5pw2qE</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-018e8de5-c9e5-4574-80a3-59f4949362d8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-018e8de5-c9e5-4574-80a3-59f4949362d8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-018e8de5-c9e5-4574-80a3-59f4949362d8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e6e2268a-51c3-4222-81be-825070e01193\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e6e2268a-51c3-4222-81be-825070e01193')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e6e2268a-51c3-4222-81be-825070e01193 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_64aab692-6139-45cf-9a2b-bcd43f991094\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('year_in_search_yt_links')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_64aab692-6139-45cf-9a2b-bcd43f991094 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('year_in_search_yt_links');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "year_in_search_yt_links",
              "summary": "{\n  \"name\": \"year_in_search_yt_links\",\n  \"rows\": 14,\n  \"fields\": [\n    {\n      \"column\": \"year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 2010,\n        \"max\": 2023,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          2014,\n          2012,\n          2023\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"yt_link\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 14,\n        \"samples\": [\n          \"https://www.youtube.com/watch?v=DVwHCGAr_OE\",\n          \"https://www.youtube.com/watch?v=xY_MUB8adEQ\",\n          \"https://www.youtube.com/watch?v=3KtWfp0UopM\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Read in table of Year in Search video links from public CSV file\n",
        "GOOGLE_YEAR_IN_SEARCH_VIDEO_LINKS_CSV_GCS_URI = (\n",
        "    \"gs://github-repo/video/google_year_in_search_video_links.csv\"\n",
        ")\n",
        "\n",
        "year_in_search_yt_links = pd.read_csv(GOOGLE_YEAR_IN_SEARCH_VIDEO_LINKS_CSV_GCS_URI)\n",
        "\n",
        "year_in_search_yt_links"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "145522e33a47"
      },
      "source": [
        "### Set up for analyzing multiple video files\n",
        "\n",
        "Let's say we are a sports agency who wants to see which athletes or teams appear most often in these videos as a measure of cultural relevance. Instead of watching and manually counting, we can use Gemini's multimodal capabilities and world knowledge to extract each appearance of an athlete or team into a structured output that we can use for further analysis.\n",
        "\n",
        "The system instructions, prompt, and response schema that will apply to all 14 videos are each created in the cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b8589a51547d"
      },
      "outputs": [],
      "source": [
        "# Set up pieces (prompt, response schema, config) for Google Year in Search videos\n",
        "multiple_video_extraction_system_instruction_text = (\n",
        "    \"You are a video analyst that \"\n",
        "    \"carefully looks through all frames of provided videos, extracting out the \"\n",
        "    \"pieces necessary to respond to user prompts.\"\n",
        ")\n",
        "\n",
        "multiple_video_extraction_prompt = (\n",
        "    \"Which sports athletes or teams are mentioned or \"\n",
        "    \"shown in this video? Please look through each frame carefully, and respond \"\n",
        "    \"with a complete list that includes the athlete or team's name (1 row per \"\n",
        "    \"athlete or team), whether they are an athlete or team, the sport they play, \"\n",
        "    \"and the timestamp into the video at which they appear (in mm:ss format, \"\n",
        "    \"do not give extra precision) for each one.\"\n",
        ")\n",
        "\n",
        "multiple_video_extraction_response_schema = {\n",
        "    \"type\": \"ARRAY\",\n",
        "    \"items\": {\n",
        "        \"type\": \"OBJECT\",\n",
        "        \"properties\": {\n",
        "            \"name\": {\"type\": \"STRING\"},\n",
        "            \"athlete_or_team\": {\"type\": \"STRING\", \"enum\": [\"athlete\", \"team\"]},\n",
        "            \"sport\": {\"type\": \"STRING\"},\n",
        "            \"video_timestamp\": {\"type\": \"STRING\"},\n",
        "        },\n",
        "    },\n",
        "}\n",
        "\n",
        "multiple_video_extraction_json_generation_config = GenerateContentConfig(\n",
        "    temperature=0.0,\n",
        "    max_output_tokens=8192,\n",
        "    response_mime_type=\"application/json\",\n",
        "    response_schema=multiple_video_extraction_response_schema,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cb2d4688f68"
      },
      "source": [
        "Next, we'll set up to run each of these prompt/video pairs through the Gemini API _asynchronously_. This allows us to send all the requests to Gemini at once, then wait for all the answers to come back - a more efficient process than sending them synchronously (one-by-one). See more details in [this Google Cloud Community Medium blog post](https://medium.com/google-cloud/how-to-prompt-gemini-asynchronously-using-python-on-google-cloud-986ca45d9f1b).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5aa93ca907bc"
      },
      "outputs": [],
      "source": [
        "# Function for asynchronous generation\n",
        "\n",
        "\n",
        "@retry(wait=wait_random_exponential(multiplier=1, max=120), stop=stop_after_attempt(2))\n",
        "async def async_generate(prompt, yt_link):\n",
        "    try:\n",
        "        response = await client.aio.models.generate_content(\n",
        "            model=GEMINI_PRO_MODEL_ID,\n",
        "            contents=[prompt, Part.from_uri(file_uri=yt_link, mime_type=\"video/webm\")],\n",
        "            config=multiple_video_extraction_json_generation_config,\n",
        "        )\n",
        "\n",
        "        return response.to_json_dict()\n",
        "    except Exception as e:\n",
        "        print(\"Something failed, retrying\")\n",
        "        print(e)\n",
        "        with retry.stop_after_attempt(2) as retry_state:\n",
        "            if retry_state.attempt > 2:\n",
        "                return None\n",
        "        raise  # Re-raise the exception for tenacity to handle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61265bdff388"
      },
      "source": [
        "### Run asynchronous Gemini calls to do video extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4191dc30d77a"
      },
      "outputs": [],
      "source": [
        "# Perform asynchronous calls across all videos, gather responses\n",
        "import asyncio\n",
        "\n",
        "start_time = asyncio.get_event_loop().time()\n",
        "\n",
        "get_responses = [\n",
        "    async_generate(multiple_video_extraction_prompt, yt_link)\n",
        "    for yt_link in year_in_search_yt_links[\"yt_link\"]\n",
        "]\n",
        "\n",
        "multiple_video_extraction_responses = await asyncio.gather(*get_responses)\n",
        "\n",
        "end_time = asyncio.get_event_loop().time()\n",
        "\n",
        "elapsed_time = end_time - start_time\n",
        "\n",
        "print(f\"Elapsed time: {elapsed_time:.2f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7c69057ae51d"
      },
      "source": [
        "### Extract and analyze video results across years\n",
        "\n",
        "Once we have the results from Gemini, we can process them and get table of every athlete or team appearance across all 14 \"Year in Search\" videos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6e424adf2cf8"
      },
      "outputs": [],
      "source": [
        "# Add structured outputs by year back to original table, show full extraction results\n",
        "year_in_search_responses = year_in_search_yt_links.copy()\n",
        "\n",
        "year_in_search_responses[\"gemini_response\"] = [\n",
        "    json.dumps(response) for response in multiple_video_extraction_responses\n",
        "]\n",
        "\n",
        "\n",
        "def extract_result_df_from_gemini_response(year, gemini_response):\n",
        "    extract_response_text = json.loads(gemini_response)[\"candidates\"][0][\"content\"][\n",
        "        \"parts\"\n",
        "    ][0][\"text\"]\n",
        "\n",
        "    extract_result_df = pd.DataFrame(json.loads(extract_response_text))\n",
        "\n",
        "    extract_result_df[\"year\"] = year\n",
        "\n",
        "    return extract_result_df\n",
        "\n",
        "\n",
        "year_in_search_responses[\"extract_result_df\"] = year_in_search_responses.apply(\n",
        "    lambda row: extract_result_df_from_gemini_response(\n",
        "        row[\"year\"], row[\"gemini_response\"]\n",
        "    ),\n",
        "    axis=1,\n",
        ")\n",
        "\n",
        "all_year_in_search_extractions = pd.concat(\n",
        "    year_in_search_responses[\"extract_result_df\"].tolist(), ignore_index=True\n",
        ")[[\"year\", \"name\", \"athlete_or_team\", \"sport\", \"video_timestamp\"]]\n",
        "\n",
        "show(all_year_in_search_extractions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b17e9b0af4e4"
      },
      "source": [
        "Finally, we can count the number of years in which each athlete or team appeared in these videos, and return results for those who appeared more than once."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0cd6041bce7"
      },
      "outputs": [],
      "source": [
        "# Analyze results to show athletes/teams showing up most often in Year in Search videos\n",
        "multiple_year_in_search_app = (\n",
        "    all_year_in_search_extractions.assign(\n",
        "        # Convert 'name' to uppercase to handle e.g. \"LeBron\" vs \"Lebron\"\n",
        "        name=all_year_in_search_extractions[\"name\"].str.upper(),\n",
        "        # Convert 'athlete_or_team' to lowercase for consistency\n",
        "        athlete_or_team=all_year_in_search_extractions[\"athlete_or_team\"].str.lower(),\n",
        "    )\n",
        "    .groupby([\"name\", \"athlete_or_team\"])\n",
        "    .apply(\n",
        "        lambda x: pd.Series(\n",
        "            {\n",
        "                # Aggregate 'sport' across type and name (handling different cases)\n",
        "                \"sport\": \", \".join(sorted(x[\"sport\"].str.lower().unique())),\n",
        "                # Count # of diff years in which each athlete/team appears in video\n",
        "                \"num_years\": x[\"year\"].nunique(),\n",
        "            }\n",
        "        )\n",
        "    )\n",
        "    .reset_index()\n",
        "    .\n",
        "    # Filter to only those appearing multiple times\n",
        "    query(\"num_years >= 2\")\n",
        "    .sort_values([\"num_years\", \"name\"], ascending=[False, True])\n",
        "    .reset_index(drop=True)\n",
        ")\n",
        "\n",
        "# Display results\n",
        "display(Markdown(\"<b>Athletes/Teams Appearing in Multiple Year in Search Videos<b>\"))\n",
        "display(multiple_year_in_search_app)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use Gemini-1.5-flash-002 to summarize a video file with audio and return chapters with timestamps. This sample works with Gemini 1.5 Pro only.\n",
        "\n",
        "https://cloud.google.com/vertex-ai/generative-ai/docs/samples/generativeaionvertexai-gemini-video-with-audio#generativeaionvertexai_gemini_video_with_audio-python"
      ],
      "metadata": {
        "id": "qV4P_HcGI2Wh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import vertexai\n",
        "from vertexai.generative_models import GenerativeModel, Part\n",
        "\n",
        "\n",
        "vertexai.init(project=PROJECT_ID, location=\"us-central1\")\n",
        "\n",
        "model = GenerativeModel(\"gemini-1.5-flash-002\")\n",
        "\n",
        "prompt = \"\"\"\n",
        "Provide a description of the video.\n",
        "The description should also contain anything important which people say in the video.\n",
        "\"\"\"\n",
        "\n",
        "video_file = Part.from_uri(\n",
        "    uri=cloud_next_keynote_video_url,\n",
        "    mime_type=\"video/webm\",\n",
        ")\n",
        "\n",
        "contents = [video_file, prompt]\n",
        "\n",
        "response = model.generate_content(contents)\n",
        "print(response.text)\n",
        "# Example response:\n",
        "# Here is a description of the video.\n",
        "# ... Then, the scene changes to a woman named Saeko Shimada..\n",
        "# She says, \"Tokyo has many faces. The city at night is totally different\n",
        "# from what you see during the day.\"\n",
        "# ..."
      ],
      "metadata": {
        "id": "hWmQo7IEJpyb",
        "outputId": "4277964e-1fe1-4090-ec9c-e6a96217b82f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Certainly! Here is a description of the video.\n",
            "\n",
            "The video opens with an animated Google Cloud Next logo. Then, it transitions to a large venue with many people in the audience. Thomas Kurian (CEO, Google Cloud) is speaking, and the large screen behind him displays various statistics and logos of companies partnering with Google Cloud.\n",
            "\n",
            "Some key points of Thomas Kurian's speech:\n",
            "\n",
            "- Since Google Cloud Next 2023, Google has introduced over 1,000 product advances across Google Cloud and Google Workspace.\n",
            "- Generative AI trainings have been taken over 1 million+ times.\n",
            "- Google is the fastest growing cloud provider.\n",
            "- Leading enterprises (McDonalds, Deutsche Bank, Mayo Clinic, HCA Healthcare, US Steel, and many more) are building generative AI apps and experiences on Google Cloud.\n",
            "- Google is helping leading companies transform their operations to become digital and AI leaders (The new way to cloud).\n",
            "- Google's AI Hypercomputer leads the industry in cost, performance, productivity, and scale for AI training and serving.\n",
            "- Google is announcing the general availability of A3 Mega VMs, powered by NVIDIA H100 Tensor Core GPUs, with twice the network bandwidth per GPU compared to A3 instances.\n",
            "- Google is announcing support for NVIDIA's Grace Hopper generation of GPUs, coming to Google Cloud early in 2025.\n",
            "- Google is accelerating inference with Hyperdisk ML, a next generation block storage service optimized for AI inference and serving workloads. It accelerates model load times up to 11.9x compared to common alternatives and offers over 100x greater throughput per volume vs. competitors.\n",
            "- Google Cloud now has both Secret and Top Secret accreditations.\n",
            "\n",
            "Sundar Pichai (CEO, Google & Alphabet) speaks about Gemini, Google's largest and most capable model yet. He says Gemini 1.5 Pro shows dramatically enhanced performance and includes a breakthrough in long context understanding. It can run 1 million tokens of information consistently, opening up new possibilities for enterprises.\n",
            "\n",
            "David Solomon (Chairman and CEO, Goldman Sachs) speaks about how Goldman Sachs is exploring different ways to use AI, such as summarizing public filings, extracting sentiment and signals from corporate statements, and gathering and interpreting information like earnings reports.\n",
            "\n",
            "Amin Vahdat (GM & VP ML Systems and Cloud AI Google Cloud) speaks about harnessing computing and data at a scale never imagined before. He announces several enhancements to Google's GPU portfolio, including the general availability of A3 Mega VMs.\n",
            "\n",
            "Aparna Pappu (GM & VP of Workspace, Google Cloud) speaks about Gemini for Google Workspace. She says it helps save time on repetitive tasks, frees up developers for higher value work, reduces agency spending, and enhances employee retention. She introduces the AI Meetings and Messaging add-on, with \"Take notes for me,\" chat summarization, and real-time translation. She also introduces the AI Security add-on and Imagen 2.0, Google's most advanced text-to-image model. She announces the preview of Text-to-Live Image.\n",
            "\n",
            "Brad Calder (GM & VP, Google Cloud) speaks about data agents grounded in enterprise data. He says that Google is introducing new query capabilities using Vertex indexing directly in BigQuery and AlloyDB. He introduces Gemini Cloud Assist, which works across your application lifecycle, making it easier to design, operate, troubleshoot, and optimize your application.\n",
            "\n",
            "Nikesh Arora (CEO, Palo Alto Networks) speaks about how Gemini has enriched their data, helping improve millions of product listings across their site, enabling customers to make better decisions when they shop with Walmart.\n",
            "\n",
            "The video concludes with Thomas Kurian thanking the customers and partners for their partnership and saying that together they're building the new way to cloud. The Google Cloud Next logo is shown again as the video ends.\n",
            "\n",
            "I hope this helps!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prompting with timestamp."
      ],
      "metadata": {
        "id": "eSJWnI0nKq_C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "Provide a description of the video.\n",
        "The description should also contain anything important which people say in the video.\n",
        "For each content extracted provide original timestamp (in .srt format) and original transcript.\n",
        "\"\"\"\n",
        "\n",
        "video_file = Part.from_uri(\n",
        "    uri=cloud_next_keynote_video_url,\n",
        "    mime_type=\"video/webm\",\n",
        ")\n",
        "\n",
        "contents = [video_file, prompt]\n",
        "\n",
        "response = model.generate_content(contents)\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "GFo4oC5kKqL2",
        "outputId": "a48d747b-f5e0-4078-f0cb-2a14a8ed7d8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Okay, here's a description of the video and a transcript of the important things said.\n",
            "\n",
            "**Google Cloud Next '23 Keynote**\n",
            "\n",
            "This video shows a keynote presentation from Google Cloud Next '23. The presenter, Thomas Kurian, CEO of Google Cloud, discusses the progress made in the less than eight months since the last Google Cloud Next event, and highlights over 1,000 product advances and over 1 million generative AI trainings completed across Google Cloud and Google Workspace.\n",
            "\n",
            "Kurian then introduces Sundar Pichai, CEO of Google and Alphabet, who talks about Gemini, Google's largest and most capable model yet. Pichai explains that Gemini 1.5 Pro offers dramatically enhanced performance and a breakthrough in long-context understanding, enabling it to consistently process 1 million tokens of information. He also mentions various companies using generative AI on Google Cloud.\n",
            "\n",
            "The keynote continues with Amin Vahdat, GM & VP ML Systems and Cloud AI at Google Cloud, announcing several enhancements to Google's GPU portfolio. These include the general availability of A3 Mega VMs powered by Nvidia H100 Tensor Core GPUs, offering twice the network bandwidth per GPU compared to A3 instances. Vahdat also introduces support for Nvidia's Grace Hopper generation of GPUs and Hyperdisk ML, a next-generation block storage service optimized for AI inference and serving workloads. He points out that the AI Hypercomputer can run with more than twice the efficiency of baseline hardware-only techniques.\n",
            "\n",
            "Further along, Aparna Pappu, GM & VP of Workspace at Google Cloud, discusses Gemini for Google Workspace. She highlights its integration with Gmail, Docs, Sheets, and other applications, ensuring enterprise-grade security and privacy. Pappu also presents AI Meetings and Messaging add-ons, including features like taking notes, chat summarization, and real-time translation.  She announces Imagen 2.0, a text-to-image model, and Text-to-Live Image, which enables the generation of animated images from text prompts.\n",
            "\n",
            "Finally, Brad Calder, GM & VP at Google Cloud, introduces Gemini Code Assist and Gemini Cloud Assist.  He emphasizes how Gemini improves speed and quality in code generation and simplifies application lifecycle management.\n",
            "\n",
            "In summary, this video presents a comprehensive overview of Google Cloud's advancements in AI, including its progress with Gemini, advancements in infrastructure, and new applications across various sectors.\n",
            "\n",
            "\n",
            "**Transcript of Important Dialogue**\n",
            "\n",
            "**0:05-0:42 Thomas Kurian:** Welcome everyone to Google Cloud Next. It's been less than eight months since Next 2023, but we made a world of progress with all of you. We've introduced over a thousand product advances across Google Cloud and Google Workspace. Our generative AI trainings have been taken over millions of times, and we've seen great success with customers and partners making us the fastest-growing cloud provider. Let's hear Sundar put this interesting time in our industry into context.\n",
            "\n",
            "**0:43-0:55 Sundar Pichai:** In December, we took our next big step with Gemini, our largest and most capable model yet. We've been bringing it to our products and to enterprises and developers through our APIs.\n",
            "\n",
            "**1:01-1:17 Sundar Pichai:** 1.5 Pro shows dramatically enhanced performance and includes a breakthrough in long context understanding. That means it can run 1 million tokens of information consistently, opening up new possibilities for enterprises to create, discover, and build using AI.\n",
            "\n",
            "**2:38-2:49 David Solomon:** We're exploring different ways to use AI, whether it's to summarize public filings, extract sentiment and signals from corporate statements, or to gather and interpret information like earnings reports.\n",
            "\n",
            "**7:53-7:58 Dara Khosrowshahi:** Our partnership with Google Cloud is helping us create a stronger and more empowered workforce.\n",
            "\n",
            "**8:00-8:03 Dara Khosrowshahi:** Gemini for Google Workspace helps us save time on repetitive tasks, frees up developers for higher value work, reduces our agency spending, and enhances employee retention.\n",
            "\n",
            "**8:13-8:20 Aparna Pappu:** Gemini for Google Workspace is our AI-powered agent built right into Gmail, Docs, Sheets, and more.\n",
            "\n",
            "**8:27-8:41 Aparna Pappu:** In a recent benchmarking study that tested the top video conferencing applications, Google Meet outperformed Microsoft Teams, Zoom, and Webex in overall video and audio performance.\n",
            "\n",
            "**10:16-10:21 Suresh Kumar:** Using Gemini, we have enriched our data, helping us improve millions of product listings across our site, and ultimately enabling customers to make better decisions when they shop with Walmart.\n",
            "\n",
            "**10:26-10:33 Suresh Kumar:** Using Gemini, we have enriched our data, helping us improve millions of product listings across our site, and ultimately enabling customers to make better decisions when they shop with Walmart.\n",
            "\n",
            "**11:16-11:31 Fiona Tan:** We chose Gemini Code Assist after running a number of pilots and evaluations that measured metrics pertaining to speed, quality, and sentiment. When we looked at the results against the control, it showed that Gemini Code Assist brought in significant improvements across the spectrum.\n",
            "\n",
            "**11:33-11:57 Brad Calder:** Our enterprise-focused AI code assistance is now called Gemini Code Assist. We've used Code Assist internally with significant impact, as shown here. We're announcing Gemini Cloud Assist, which works across your application lifecycle, making it easier to design, operate, troubleshoot, and optimize your application.\n",
            "\n",
            "**12:18-12:24 Nikesh Arora:** Very excited about all the capabilities that Gemini brings to the fore. We noticed this large language model has allowed us to do things a little faster, get more precise, and we're hitting numbers north of 90% in terms of accuracy.\n",
            "\n",
            "I hope this helps!\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "youtube_video_analysis.ipynb",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}